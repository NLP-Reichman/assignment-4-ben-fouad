{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-WJBimYDLJS"
      },
      "source": [
        "# Natural Language Processing\n",
        "![](https://i.imgur.com/qkg2E2D.png)\n",
        "\n",
        "## Assignment 004 - BERT-based NER Tagger\n",
        "\n",
        "> Notebook by:\n",
        "> - NLP Course Stuff\n",
        "## Revision History\n",
        "\n",
        "| Version | Date       | User        | Content / Changes                                                   |\n",
        "|---------|------------|-------------|---------------------------------------------------------------------|\n",
        "| 0.1.000 | 09/06/2024 | course staff| First version                                                       |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-fCqGh9ybgm"
      },
      "source": [
        "## Overview\n",
        "In this assignment, you will further work on assignment 3, that is, you will build a complete training and testing pipeline for a neural sequential tagger for named entities using BERT, this time.\n",
        "\n",
        "**This assignment is not mandatory, we will take the 3/4 best grades, but we recomment you doing it.**\n",
        "\n",
        "## Dataset\n",
        "You will work with the ReCoNLL 2003 dataset, a corrected version of the [CoNLL 2003 dataset](https://www.clips.uantwerpen.be/conll2003/ner/):\n",
        "\n",
        "**Click on those links so you have access to the data!**\n",
        "- [Train data](https://drive.google.com/file/d/1CqEGoLPVKau3gvVrdG6ORyfOEr1FSZGf/view?usp=sharing)\n",
        "\n",
        "- [Dev data](https://drive.google.com/file/d/1rdUida-j3OXcwftITBlgOh8nURhAYUDw/view?usp=sharing)\n",
        "\n",
        "- [Test data](https://drive.google.com/file/d/137Ht40OfflcsE6BIYshHbT5b2iIJVaDx/view?usp=sharing)\n",
        "\n",
        "As you will see, the annotated texts are labeled according to the `IOB` annotation scheme (more on this below), for 3 entity types: Person, Organization, Location.\n",
        "\n",
        "## Your Implementation\n",
        "\n",
        "Please create a local copy of this template Colab's Notebook:\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1KGkObwUn5QQm_v0nB0nAUlB4YrwThuzl#scrollTo=Z-fCqGh9ybgm)\n",
        "\n",
        "The assignment's instructions are there; follow the notebook.\n",
        "\n",
        "## Submission\n",
        "- **Notebook Link**: Add the URL to your assignment's notebook in the `notebook_link.txt` file, following the format provided in the example.\n",
        "- **Access**: Ensure the link has edit permissions enabled to allow modifications if needed.\n",
        "- **Deadline**: <font color='green'>27/06/2024</font>.\n",
        "- **Platform**: Continue using GitHub for submissions. Push your project to the team repository and monitor the test results under the actions section.\n",
        "\n",
        "Good Luck ðŸ¤—\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOy8IghquR6x"
      },
      "source": [
        "<!-- ## NER schemes:  \n",
        "\n",
        "> `IO`: is the simplest scheme that can be applied to this task. In this scheme, each token from the dataset is assigned one of two tags: an inside tag (`I`) and an outside tag (`O`). The `I` tag is for named entities, whereas the `O` tag is for normal words. This scheme has a limitation, as it cannot correctly encode consecutive entities of the same type.\n",
        "\n",
        "> `IOB`: This scheme is also referred to in the literature as BIO and has been adopted by the Conference on Computational Natural Language Learning (CoNLL) [1]. It assigns a tag to each word in the text, determining whether it is the beginning (`B`) of a known named entity, inside (`I`) it, or outside (`O`) of any known named entities.\n",
        "\n",
        "> `IOE`: This scheme works nearly identically to `IOB`, but it indicates the end of the entity (`E` tag) instead of its beginning.\n",
        "\n",
        "> `IOBES`: An alternative to the IOB scheme is `IOBES`, which increases the amount of information related to the boundaries of named entities. In addition to tagging words at the beginning (`B`), inside (`I`), end (`E`), and outside (`O`) of a named entity. It also labels single-token entities with the tag `S`.\n",
        "\n",
        "> `BI`: This scheme tags entities in a similar method to `IOB`. Additionally, it labels the beginning of non-entity words with the tag B-O and the rest as I-O.\n",
        "\n",
        "> `IE`: This scheme works exactly like `IOE` with the distinction that it labels the end of non-entity words with the tag `E-O` and the rest as `I-O`.\n",
        "\n",
        "> `BIES`: This scheme encodes the entities similar to `IOBES`. In addition, it also encodes the non-entity words using the same method. It uses `B-O` to tag the beginning of non-entity words, `I-O` to tag the inside of non-entity words, and `S-O` for single non-entity tokens that exist between two entities. -->\n",
        "\n",
        "\n",
        "## NER Schemes\n",
        "\n",
        "### IO\n",
        "- **Description**: The simplest scheme for named entity recognition (NER).\n",
        "- **Tags**:\n",
        "  - `I`: Inside a named entity.\n",
        "  - `O`: Outside any named entity.\n",
        "- **Limitation**: Cannot correctly encode consecutive entities of the same type.\n",
        "\n",
        "### IOB (BIO)\n",
        "- **Description**: Adopted by the Conference on Computational Natural Language Learning (CoNLL).\n",
        "- **Tags**:\n",
        "  - `B`: Beginning of a named entity.\n",
        "  - `I`: Inside a named entity.\n",
        "  - `O`: Outside any named entity.\n",
        "- **Advantage**: Can encode the boundaries of consecutive entities.\n",
        "\n",
        "### IOE\n",
        "- **Description**: Similar to IOB, but indicates the end of an entity.\n",
        "- **Tags**:\n",
        "  - `I`: Inside a named entity.\n",
        "  - `O`: Outside any named entity.\n",
        "  - `E`: End of a named entity.\n",
        "- **Advantage**: Focuses on the end boundary of entities.\n",
        "\n",
        "### IOBES\n",
        "- **Description**: An extension of IOB with additional boundary information.\n",
        "- **Tags**:\n",
        "  - `B`: Beginning of a named entity.\n",
        "  - `I`: Inside a named entity.\n",
        "  - `O`: Outside any named entity.\n",
        "  - `E`: End of a named entity.\n",
        "  - `S`: Single-token named entity.\n",
        "- **Advantage**: Provides more detailed boundary information for named entities.\n",
        "\n",
        "### BI\n",
        "- **Description**: Tags entities similarly to IOB and labels the beginning of non-entity words.\n",
        "- **Tags**:\n",
        "  - `B`: Beginning of a named entity.\n",
        "  - `I`: Inside a named entity.\n",
        "  - `B-O`: Beginning of a non-entity word.\n",
        "  - `I-O`: Inside a non-entity word.\n",
        "- **Advantage**: Distinguishes the beginning of non-entity sequences.\n",
        "\n",
        "### IE\n",
        "- **Description**: Similar to IOE but for non-entity words.\n",
        "- **Tags**:\n",
        "  - `I`: Inside a named entity.\n",
        "  - `O`: Outside any named entity.\n",
        "  - `E`: End of a named entity.\n",
        "  - `E-O`: End of a non-entity word.\n",
        "  - `I-O`: Inside a non-entity word.\n",
        "- **Advantage**: Highlights the end of non-entity sequences.\n",
        "\n",
        "### BIES\n",
        "- **Description**: Encodes both entities and non-entity words using the IOBES method.\n",
        "- **Tags**:\n",
        "  - `B`: Beginning of a named entity.\n",
        "  - `I`: Inside a named entity.\n",
        "  - `O`: Outside any named entity.\n",
        "  - `E`: End of a named entity.\n",
        "  - `S`: Single-token named entity.\n",
        "  - `B-O`: Beginning of a non-entity word.\n",
        "  - `I-O`: Inside a non-entity word.\n",
        "  - `S-O`: Single non-entity token.\n",
        "- **Advantage**: Comprehensive encoding for both entities and non-entities.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRwONXCzi28v"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n",
        "# Fetch data\n",
        "# train_link = 'https://drive.google.com/file/d/1CqEGoLPVKau3gvVrdG6ORyfOEr1FSZGf/view?usp=sharing'\n",
        "# dev_link   = 'https://drive.google.com/file/d/1rdUida-j3OXcwftITBlgOh8nURhAYUDw/view?usp=sharing'\n",
        "# test_link  = 'https://drive.google.com/file/d/137Ht40OfflcsE6BIYshHbT5b2iIJVaDx/view?usp=sharing'\n",
        "\n",
        "!wget -q --no-check-certificate 'https://docs.google.com/uc?export=download&id=1CqEGoLPVKau3gvVrdG6ORyfOEr1FSZGf' -O data/train.txt\n",
        "!wget -q --no-check-certificate 'https://docs.google.com/uc?export=download&id=1rdUida-j3OXcwftITBlgOh8nURhAYUDw' -O data/dev.txt\n",
        "!wget -q --no-check-certificate 'https://docs.google.com/uc?export=download&id=137Ht40OfflcsE6BIYshHbT5b2iIJVaDx' -O data/test.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QNUSyEwvWqn"
      },
      "outputs": [],
      "source": [
        "# Any additional needed libraries\n",
        "!pip install -qU transformers[torch] wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3enPCGBF8FlX"
      },
      "outputs": [],
      "source": [
        "# Standard Library Imports\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from typing import Optional\n",
        "import json\n",
        "from google.colab import files\n",
        "\n",
        "# ML\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "\n",
        "# Visual\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# DL\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Metrics\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score , roc_auc_score, classification_report, confusion_matrix, precision_recall_fscore_support\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUM4WJ9PwF0x"
      },
      "outputs": [],
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "SEED = 42\n",
        "# Set the random seed for Python\n",
        "random.seed(SEED)\n",
        "\n",
        "# Set the random seed for numpy\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Set the random seed for pytorch\n",
        "th.manual_seed(SEED)\n",
        "\n",
        "# If using CUDA (for GPU operations)\n",
        "th.cuda.manual_seed(SEED)\n",
        "\n",
        "# Set up the device\n",
        "DEVICE = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
        "# assert DEVICE == \"cuda\"\n",
        "\n",
        "DataType = dict[str, list[list[str]]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-1shPaJ0z1B"
      },
      "source": [
        "# Part 1 - Dataset Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ul2Y3vuPoV8"
      },
      "source": [
        "## Step 1: Read Data\n",
        "Write a function for reading the data from a single file (of the ones that are provided above).   \n",
        "- The function recieves a filepath\n",
        "- The funtion encodes every sentence individually using a pair of lists, one list contains the words and one list contains the tags.\n",
        "- The function returns a dictionary of the texts as a list and the tags as a list.\n",
        "\n",
        "Example output:\n",
        "```\n",
        "{\n",
        "  \"texts\": [\n",
        "    ['At','Trent','Bridge',':'],\n",
        "    ...],\n",
        "  \"tags\":[\n",
        "    ['O','B-LOC','I-LOC ','O'],\n",
        "    ...]\n",
        "  ...\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prgzgtt8Jw4Y"
      },
      "outputs": [],
      "source": [
        "def read_data(filepath:str) -> DataType:\n",
        "  \"\"\"\n",
        "  Read data from a single file.\n",
        "  The function recieves a filepath\n",
        "  The funtion encodes every sentence using a pair of lists, one list contains the words and one list contains the tags.\n",
        "  :param filepath: path to the file\n",
        "  :return: data as a list of tuples\n",
        "  \"\"\"\n",
        "  data = {\n",
        "    \"texts\": [],\n",
        "    \"tags\": []\n",
        "  }\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "  with open(filepath, 'r', encoding='utf-8') as file:\n",
        "        sentence = []\n",
        "        tags = []\n",
        "        \n",
        "        for line in file:\n",
        "            if line.strip() == '':\n",
        "                # Check that the sentence and tags lists are not empty\n",
        "                if sentence and tags:  \n",
        "                    data[\"texts\"].append(sentence)\n",
        "                    data[\"tags\"].append(tags)\n",
        "                sentence = []\n",
        "                tags = []\n",
        "            else:\n",
        "                splits = line.strip().split()\n",
        "                word = splits[0]\n",
        "                tag = splits[-1]\n",
        "                sentence.append(word)\n",
        "                tags.append(tag)\n",
        "        \n",
        "        # Add the last sentence if it's non-empty and not added\n",
        "        if sentence and tags:\n",
        "            data[\"texts\"].append(sentence)\n",
        "            data[\"tags\"].append(tags)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yURR0GmX2i8M"
      },
      "outputs": [],
      "source": [
        "train_raw = read_data(\"data/train.txt\")\n",
        "dev_raw = read_data(\"data/dev.txt\")\n",
        "test_raw = read_data(\"data/test.txt\")\n",
        "print(f\"Train size: {len(train_raw['texts'])}\")\n",
        "print(f\"Dev size: {len(dev_raw['texts'])}\")\n",
        "print(f\"Test size: {len(test_raw['texts'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDKYryfKfNdh"
      },
      "source": [
        "## Step 2: Prepare Data\n",
        "Write a function `prepare_data` that takes one of the [train, dev, test], and encodes it to tensors.\n",
        "\n",
        "### Your Task\n",
        "1. Load the BERT Tokenizer\n",
        "2. Tokenize the data and encode the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bodTbOuigE5v"
      },
      "outputs": [],
      "source": [
        "# Prepare tag2id dictionaries\n",
        "tag2id = {}\n",
        "id2tag = {}\n",
        "tags = [\"O\", \"B-PER\", \"I-PER\", \"B-LOC\", \"I-LOC\", \"B-ORG\", \"I-ORG\"]\n",
        "for tag in tags:\n",
        "  tag2id[tag] = len(tag2id)\n",
        "  id2tag[len(id2tag)] = tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGgKthOCjm3F"
      },
      "outputs": [],
      "source": [
        "tag2id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glC9DIFmZrG4"
      },
      "outputs": [],
      "source": [
        "tokenizer = None\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noIY3zWKvhBd"
      },
      "outputs": [],
      "source": [
        "def prepare_data(data: DataType, tag2id: dict[str, int]) -> dict[str, th.Tensor]:\n",
        "  enc_data = {\n",
        "    \"texts\": None,\n",
        "    \"labels\": None\n",
        "  }\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "  # Tokenize the texts\n",
        "\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "  return enc_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tqhbs5yRiHz-"
      },
      "outputs": [],
      "source": [
        "train_sequences = prepare_data(train_raw, tag2id)\n",
        "dev_sequences = prepare_data(dev_raw, tag2id)\n",
        "test_sequences = prepare_data(test_raw, tag2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxC7SyD0EaMF"
      },
      "source": [
        "## Step 3: Dataset\n",
        "Create datasets for each split in the dataset. They should return the samples as Tensors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zrosQU95vYZ"
      },
      "outputs": [],
      "source": [
        "class NERDataset(Dataset):\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "  # TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mddZ1z7g4Bx9"
      },
      "outputs": [],
      "source": [
        "train_ds = None\n",
        "dev_ds = None\n",
        "test_ds = None\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "train_ds = NERDataset(train_sequences)\n",
        "dev_ds = NERDataset(dev_sequences)\n",
        "test_ds = NERDataset(test_sequences)\n",
        "# TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeLdRU9R-pm3"
      },
      "source": [
        "<br><br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUsgtdW869JH"
      },
      "source": [
        "# Part 2 - NER Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UccfiRRtiEet"
      },
      "source": [
        "## Step 1: Load Model\n",
        "\n",
        "Load a token classification model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ke1LyUQNyQaM"
      },
      "outputs": [],
      "source": [
        "model = None\n",
        "def load_model(model_name: str, tag2id) -> nn.Module:\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "model = load_model(model_name, tag2id)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEGSQdeUkTP8"
      },
      "source": [
        "## Step 2: Training\n",
        "\n",
        "Write a training function that utilizes the huggingface Trainer. The function should log the loss of both train dataset and the dev one every here and there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEUELdls5hFJ"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 5\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "BATCH_SIZE = 0\n",
        "# TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avkHfjT3k0HM"
      },
      "outputs": [],
      "source": [
        "def train_model(model, n_epochs: int, batch_size: int, train_ds: Dataset, dev_ds: Dataset) -> Trainer:\n",
        "  \"\"\"\n",
        "  Train a model.\n",
        "  :param model: model instance\n",
        "  :param n_epochs: number of epochs to train on\n",
        "  :param batch_size: batch size\n",
        "  :param train_ds: train dataset\n",
        "  :param dev_ds: dev dataset\n",
        "  :return: loss and accuracy during training\n",
        "  \"\"\"\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "  # TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KC1nYSi18PV"
      },
      "outputs": [],
      "source": [
        "wandb.watch(model, log_freq=15)\n",
        "trainer = train_model(model, N_EPOCHS, BATCH_SIZE, train_ds, dev_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9C9su31_r7F"
      },
      "source": [
        "<br><br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqSMEZDK9OPY"
      },
      "source": [
        "# Part 3 - Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baN1c_B7lTjb"
      },
      "source": [
        "\n",
        "## Step 1: Evaluation Function\n",
        "\n",
        "Write an evaluation function for a trained model using the dev and test datasets. This function will print the `Recall`, `Precision`, and `F1` scores and plot a `Confusion Matrix`.\n",
        "\n",
        "Perform this evaluation twice:\n",
        "1. For all labels (7 labels in total).\n",
        "2. For all labels except \"O\" (6 labels in total)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6MhtYgh7hDO"
      },
      "source": [
        "## Metrics and Display\n",
        "\n",
        "### Metrics\n",
        "- **Recall**: True Positive Rate (TPR), also known as Recall.\n",
        "- **Precision**: The opposite of False Positive Rate (FPR), also known as Precision.\n",
        "- **F1 Score**: The harmonic mean of Precision and Recall.\n",
        "\n",
        "*Note*: For all these metrics, use **weighted** averaging:\n",
        "Calculate metrics for each label, and find their average weighted by support. Refer to the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html#sklearn.metrics.precision_recall_fscore_support) for more details.\n",
        "\n",
        "### Display\n",
        "1. Print the `Recall`, `Precision`, and `F1` scores in a tabulated format.\n",
        "2. Display a `Confusion Matrix` plot:\n",
        "   - Rows represent the predicted labels.\n",
        "   - Columns represent the true labels.\n",
        "   - Include a title for the plot, axis names, and the names of the tags on the X-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyQAjGaqmd8U"
      },
      "outputs": [],
      "source": [
        "def evaluate(trainer: Trainer, title: str, dataset: Dataset, tag2id: dict[str, int]):\n",
        "  \"\"\"\n",
        "  Evaluate a trained model on the given dataset.\n",
        "  :param trainer: trainer instance containing a trained model\n",
        "  :param title: title for the plot\n",
        "  :param dataset: dataset\n",
        "  :param tag2id: tag2id dictionary\n",
        "  :return: Dictionary of evaluation results\n",
        "  \"\"\"\n",
        "  results = {}\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "\n",
        "  # TO DO ----------------------------------------------------------------------\n",
        "  return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wIoXsjhUZ0B"
      },
      "outputs": [],
      "source": [
        "# Assuming model is trained, and dl_dev is the DataLoader for dev dataset\n",
        "results = evaluate(trainer, \"Evaluation on Dev Set\", dev_ds, tag2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP5FbhQphO3z"
      },
      "source": [
        "## Step 2 - Logs and Visualization\n",
        "Explore and intagrate [wandb](https://wandb.ai/home) as a logging and visualization tool. Integrate it in the training and evaluation steps. Look for the plots of the loss (train, eval) and see how useful it can be :) Also make sure to log some results, such as plots and funal results before printing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trn5-50FyGoF"
      },
      "source": [
        "## Step 3: Development\n",
        "Experiment your training with diffenet Hyperparameters and optimize them based on the results on the **development set**.\n",
        "\n",
        "Decide which model performs the best. Note that this time the parameters changes will be inside the model initialization or the train functions and will not be given as parameters to the load_model function. So just hard-code them in the other functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWJREQ236dzV"
      },
      "outputs": [],
      "source": [
        "# TO DO ----------------------------------------------------------------------\n",
        "\n",
        "# TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y4U4eHmShw8"
      },
      "source": [
        "## Step 4 - Final Evaluation\n",
        "After configring your params such that the model loaded is the best one,train it, evaluate it on the test set and print the results. This part simulates the real world data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M3TnKYqmSvds"
      },
      "outputs": [],
      "source": [
        "model = None\n",
        "# TO DO ----------------------------------------------------------------------\n",
        "\n",
        "# TO DO ----------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsCfk8caB3iU"
      },
      "source": [
        "<br><br><br><br><br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMVrbY0SCRja"
      },
      "outputs": [],
      "source": [
        "####################\n",
        "# PLACE TESTS HERE #\n",
        "####################\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
